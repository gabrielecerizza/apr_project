{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from src.utils import (\n",
    "    create_dataset, plot_spectrogram,\n",
    "    RandomClip, extract_logmel, pad_tensor, plot_waveform\n",
    ")\n",
    "from src.datasets import VoxCelebDataModule\n",
    "from src.models import SEBlock, SpeakerRecognitionModel, build_efficientnetv2\n",
    "from torch import nn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src.losses import SubCenterAAMSoftmaxLoss\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_curve, accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from src.utils import (\n",
    "    RandomBackgroundNoise, RandomClip, RandomSpeedChange,\n",
    "    create_features_from_row, kmeans_plot\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "from pedalboard import Pedalboard, Reverb, Chorus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_WAV_SPEECH_PATH = \"E:\\Datasets\\VoxCeleb1\\\\vox1_dev\\id10015\\\\7rzuEmfRFEA\\\\00001.wav\"\n",
    "waveform, sample_rate = torchaudio.load(SAMPLE_WAV_SPEECH_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec = torch.load(\"E:\\Datasets\\VoxCeleb1\\subset\\\\verification_None\\\\test\\id10153\\\\x29OJk3Ec-Q\\\\00001_.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec = extract_logmel(waveform, n_mels=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_t = torchaudio.transforms.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = mfcc_t(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(melspec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr = torchaudio.transforms.Spectrogram()\n",
    "sprr = spr(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprr2 = librosa.feature.melspectrogram(\n",
    "    y=waveform.numpy()[0],\n",
    "    sr=16000,\n",
    "    power=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(np.log(sprr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_WAV_SPEECH_PATH = \"/media/gabriele/Seagate Expansion Drive/Datasets/VoxCeleb1/vox1_dev/id10001/1zcIwhmdeo4/00001.wav\"\n",
    "waveform, sample_rate = torchaudio.load(SAMPLE_WAV_SPEECH_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb = Pedalboard(\n",
    "    [Reverb(room_size=0.75)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Pedalboard([Chorus(), Reverb(room_size=0.25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board(waveform, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb(waveform, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = RandomClip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = rc(waveform)\n",
    "clipped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 512\n",
    "mel_spectrogram = T.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        win_length=400,\n",
    "        hop_length=160,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=2.0, # energy instead of power\n",
    "        norm=\"slaney\",\n",
    "        onesided=True,\n",
    "        n_mels=80,\n",
    "        mel_scale=\"htk\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmn = T.SlidingWindowCmn(cmn_window=n_fft)\n",
    "to_db = T.AmplitudeToDB(stype=\"amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel = mel_spectrogram(clipped)\n",
    "logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel = extract_logmel(clipped, sample_rate=16000, n_mels=80)\n",
    "logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel = torch.load(\"E:\\Datasets\\VoxCeleb1\\subset\\\\features_3\\\\train\\id10075\\\\08H4--mL1LQ\\\\00001_.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logeml = logmel + 1e-6\n",
    "logeml = torch.log(logeml)\n",
    "logmel = F.instance_norm(logmel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(melspec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_masking = T.FrequencyMasking(freq_mask_param=10)\n",
    "time_masking = T.TimeMasking(time_mask_param=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_logmel = time_masking(freq_masking(logmel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(time_masking(freq_masking(logmel))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_secs = 3\n",
    "csv_base_path: str = \"E:/Datasets/VoxCeleb1/subset/\"\n",
    "label_dict = pd.read_csv(\n",
    "    csv_base_path + f\"subset_labels_{num_secs}.csv\"\n",
    ").to_dict()[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_ids = list(label_dict.keys())\n",
    "len(speaker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train    11828\n",
      "test       665\n",
      "val        549\n",
      "Name: Set, dtype: int64\n",
      "Num speakers: 100\n",
      "Male ratio in dataset: 0.5515587529976019\n",
      "Female ratio in dataset: 0.44844124700239807\n",
      "Male sampled ratio: 0.55\n",
      "Female sampled ratio: 0.45\n",
      "Num sampled males: 55\n",
      "Num sampled females: 45\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        \r"
     ]
    }
   ],
   "source": [
    "create_dataset(\n",
    "    num_speakers=100, \n",
    "    to_db_flag=True,\n",
    "    cmn_flag=True,\n",
    "    clip_secs=4,\n",
    "    n_fft=400,\n",
    "    win_length=400,\n",
    "    hop_length=160,\n",
    "    n_mels=80,\n",
    "    power=1.0,\n",
    "    data_aug=True,\n",
    "    speaker_ids=speaker_ids,\n",
    "    full_test=True,\n",
    "    wave_test=True\n",
    "    # base_path=\"/media/gabriele/Seagate Expansion Drive/Datasets/VoxCeleb1/\",\n",
    "    # noise_dir=\"/media/gabriele/Seagate Expansion Drive/Datasets/Musan/noise\",\n",
    "    # babble_dir=\"/media/gabriele/Seagate Expansion Drive/Datasets/Musan/speech\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Datasets\\VoxCeleb1\\subset\\subset_labels_3.csv\")\n",
    "speaker_ids = df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(\n",
    "    num_speakers=5,\n",
    "    clip_secs=6, \n",
    "    to_db_flag=True, \n",
    "    cmn_flag=True,\n",
    "    speaker_ids=speaker_ids\n",
    "    # base_path=\"/media/gabriele/Seagate Expansion Drive/Datasets/VoxCeleb1/\",\n",
    "    # noise_dir=\"/media/gabriele/Seagate Expansion Drive/Datasets/Musan/noise\",\n",
    "    # babble_dir=\"/media/gabriele/Seagate Expansion Drive/Datasets/Musan/speech\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_secs = 3\n",
    "csv_base_path: str = \"E:/Datasets/VoxCeleb1/subset/\"\n",
    "set_name: str = \"train\"\n",
    "df = pd.read_csv(\n",
    "            csv_base_path + f\"subset_features_{num_secs}.csv\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df[\"Set\"] == \"train\"]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pd.read_csv(\n",
    "            csv_base_path + f\"subset_labels_{num_secs}.csv\"\n",
    "        ).to_dict()[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspecs = []\n",
    "y = []\n",
    "for idx, row in df.iterrows():\n",
    "    melspec = torch.load(row[\"File\"]).numpy()\n",
    "    melspecs.append(\n",
    "        melspec\n",
    "    )\n",
    "    y.append(\n",
    "        label_dict[row[\"Speaker\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(melspecs)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], 80*301)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.vstack(y).squeeze(-1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_y = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpca[y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in u_y:\n",
    "    plt.scatter(\n",
    "        Xpca[y == label, 0], \n",
    "        Xpca[y == label, 1], \n",
    "        label=label,\n",
    "        alpha=0.7\n",
    "    )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    [torch.randn((4,5))], \n",
    "    lr=1e-3, \n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.state_dict()[\"param_groups\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = torch.load(\n",
    "    \"E:\\Datasets\\VoxCeleb1\\subset\\\\features_4\\\\train\\id10206\\\\0dATli9-ofc\\\\00001_.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel = extract_logmel(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pad_tensor(\n",
    "    logmel, 401, 450\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_secs = 3\n",
    "csv_base_path: str = \"E:/Datasets/VoxCeleb1/subset/\"\n",
    "label_dict = pd.read_csv(\n",
    "    csv_base_path + f\"subset_labels_{num_secs}.csv\"\n",
    ").to_dict()[\"label\"]\n",
    "\n",
    "speaker_ids = list(label_dict.keys())\n",
    "len(speaker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_verification_dataset(\n",
    "    speaker_ids,\n",
    "    num_speakers: int = 10,\n",
    "    base_path: str = \"E:/Datasets/VoxCeleb1/\",\n",
    "    n_mels: int = 80,\n",
    "    power: float = 1.0, # 1 for energy, 2 for power\n",
    "    to_db_flag: bool = True,\n",
    "    cmn_flag: bool = True,\n",
    "    n_fft: int = 400,\n",
    "    win_length: int = None,\n",
    "    hop_length: int = 160,\n",
    "    data_aug: bool = False,\n",
    "    full_test: bool=True\n",
    "):\n",
    "    ls = []\n",
    "    with open(base_path + \"iden_split.txt\") as file:\n",
    "        \n",
    "        gender_df = pd.read_csv(base_path + \"vox1_meta.csv\", sep=\"\\t\")\n",
    "        m_ratio = gender_df[\"Gender\"].value_counts(normalize=True)[\"m\"]\n",
    "        f_ratio = gender_df[\"Gender\"].value_counts(normalize=True)[\"f\"]\n",
    "        n_males = int(num_speakers * m_ratio)\n",
    "        n_females = num_speakers - n_males\n",
    "\n",
    "        restricted_df = gender_df[~gender_df[\"VoxCeleb1 ID\"].isin(speaker_ids)]\n",
    "        \n",
    "        male_ids = random.sample(\n",
    "            list(\n",
    "                restricted_df[restricted_df[\"Gender\"] == \"m\"][\"VoxCeleb1 ID\"].unique()\n",
    "            ),\n",
    "            n_males\n",
    "        )\n",
    "        female_ids = random.sample(\n",
    "            list(\n",
    "                restricted_df[restricted_df[\"Gender\"] == \"f\"][\"VoxCeleb1 ID\"].unique()\n",
    "            ),\n",
    "            n_females\n",
    "        )\n",
    "        chosen_ids = male_ids + female_ids\n",
    "\n",
    "        print(chosen_ids)\n",
    "\n",
    "        for line in file:\n",
    "            set_num, audio_path = line.split()\n",
    "            speaker_id = audio_path.split(\"/\")[0]\n",
    "            if speaker_id not in chosen_ids:\n",
    "                continue\n",
    "            gender = list(\n",
    "                gender_df[gender_df[\"VoxCeleb1 ID\"] == speaker_id][\"Gender\"]\n",
    "            )[0]\n",
    "            ls.append((set_num, speaker_id, gender, audio_path))\n",
    "\n",
    "    df = pd.DataFrame(ls, columns =[\"Set\", \"Speaker\", \"Gender\", \"File\"])\n",
    "    df[\"Set\"] = df[\"Set\"].apply(\n",
    "        lambda x: \"train\" if x == \"1\" else \"val\" if x == \"2\" else \"test\"\n",
    "    )\n",
    "\n",
    "    m_sampled_ratio = df.drop_duplicates(\"Speaker\")[\"Gender\"].value_counts(normalize=True)[\"m\"]\n",
    "    f_sampled_ratio = df.drop_duplicates(\"Speaker\")[\"Gender\"].value_counts(normalize=True)[\"f\"]\n",
    "\n",
    "    print(\n",
    "        f\"Num speakers: {num_speakers}\\n\"\n",
    "        f\"Male ratio in dataset: {m_ratio}\\n\"\n",
    "        f\"Female ratio in dataset: {f_ratio}\\n\"\n",
    "        f\"Male sampled ratio: {m_sampled_ratio}\\n\"\n",
    "        f\"Female sampled ratio: {f_sampled_ratio}\\n\"\n",
    "        f\"Num sampled males: {n_males}\\n\"\n",
    "        f\"Num sampled females: {n_females}\\n\"\n",
    "    )\n",
    "\n",
    "    ls = []\n",
    "    for index, row in tqdm(\n",
    "        df.iterrows(),\n",
    "        total=len(df),\n",
    "        desc=\"Creating verification dataset\",\n",
    "        leave=False\n",
    "    ):\n",
    "        # copy_audio(row, base_path)\n",
    "        feat_ls = create_features_from_row(\n",
    "            row=row, \n",
    "            base_path=base_path,\n",
    "            rsc=None,\n",
    "            rbn=None,\n",
    "            reverb=None,\n",
    "            babble=None,\n",
    "            random_clip=None,\n",
    "            clip_secs=None,\n",
    "            n_mels=n_mels,\n",
    "            power=power,\n",
    "            to_db_flag=to_db_flag,\n",
    "            cmn_flag=cmn_flag,\n",
    "            n_fft=n_fft,\n",
    "            win_length=win_length,\n",
    "            hop_length=hop_length,\n",
    "            data_aug=data_aug,\n",
    "            features_dir=\"verification\"\n",
    "        )\n",
    "        ls.extend(feat_ls)\n",
    "\n",
    "    df = pd.DataFrame(\n",
    "        ls, \n",
    "        columns = [\n",
    "            \"Set\", \"Speaker\", \"Type\", \"Augment\", \n",
    "            \"Seconds\", \"Path\", \"File\"\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    csv_base_path = base_path + \"subset/\"\n",
    "\n",
    "    df.to_csv(\n",
    "        csv_base_path + f\"subset_verification.csv\", \n",
    "        index_label=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_verification_dataset(\n",
    "    speaker_ids=speaker_ids,\n",
    "    num_speakers=10\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3a0b09ceef9b827a17ce91fbca1b0359a993a122e166af5f0b6d31a5625f693"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tf_p3.9': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
