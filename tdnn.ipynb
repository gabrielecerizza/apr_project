{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torchaudio\n",
    "import torch.nn.functional as F\n",
    "import torchaudio.transforms as T\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Audio, display\n",
    "import json\n",
    "import numpy as np\n",
    "import math\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "sns.set_style(\"ticks\")\n",
    "sns.set_context(\"paper\")\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "from datetime import timedelta\n",
    "\n",
    "from src.utils import (\n",
    "    create_dataset, plot_spectrogram,\n",
    "    RandomClip, extract_logmel, pad_tensor, plot_waveform,\n",
    "    train_sklearn_model, get_dataset_stats\n",
    ")\n",
    "from src.datasets import VoxCelebDataModule\n",
    "from src.models import SEBlock, SpeakerRecognitionModel, build_efficientnetv2\n",
    "from torch import nn\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from src.losses import SubCenterAAMSoftmaxLoss\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import roc_curve, accuracy_score, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from src.utils import (\n",
    "    RandomBackgroundNoise, RandomClip, RandomSpeedChange,\n",
    "    create_features_from_row, kmeans_plot, create_verification_dataset\n",
    ")\n",
    "from tqdm.auto import tqdm\n",
    "from pedalboard import Pedalboard, Reverb, Chorus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_WAV_SPEECH_PATH = \"E:\\Datasets\\VoxCeleb1\\\\vox1_dev\\id10015\\\\7rzuEmfRFEA\\\\00001.wav\"\n",
    "waveform, sample_rate = torchaudio.load(SAMPLE_WAV_SPEECH_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec = torch.load(\"E:\\Datasets\\VoxCeleb1\\subset\\\\verification_None\\\\test\\id10153\\\\x29OJk3Ec-Q\\\\00001_.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspec = extract_logmel(waveform, n_mels=80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc_t = torchaudio.transforms.MFCC(\n",
    "    sample_rate=16000,\n",
    "    n_mfcc=40\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc = mfcc_t(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(melspec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spr = torchaudio.transforms.Spectrogram()\n",
    "sprr = spr(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sprr2 = librosa.feature.melspectrogram(\n",
    "    y=waveform.numpy()[0],\n",
    "    sr=16000,\n",
    "    power=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(np.log(sprr2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_WAV_SPEECH_PATH = \"/media/gabriele/Seagate Expansion Drive/Datasets/VoxCeleb1/vox1_dev/id10001/1zcIwhmdeo4/00001.wav\"\n",
    "waveform, sample_rate = torchaudio.load(SAMPLE_WAV_SPEECH_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb = Pedalboard(\n",
    "    [Reverb(room_size=0.75)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board = Pedalboard([Chorus(), Reverb(room_size=0.25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "board(waveform, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverb(waveform, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = RandomClip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped = rc(waveform)\n",
    "clipped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fft = 512\n",
    "mel_spectrogram = T.MelSpectrogram(\n",
    "        sample_rate=sample_rate,\n",
    "        n_fft=n_fft,\n",
    "        win_length=400,\n",
    "        hop_length=160,\n",
    "        center=True,\n",
    "        pad_mode=\"reflect\",\n",
    "        power=2.0, # energy instead of power\n",
    "        norm=\"slaney\",\n",
    "        onesided=True,\n",
    "        n_mels=80,\n",
    "        mel_scale=\"htk\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmn = T.SlidingWindowCmn(cmn_window=n_fft)\n",
    "to_db = T.AmplitudeToDB(stype=\"amplitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel = mel_spectrogram(clipped)\n",
    "logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel = extract_logmel(clipped, sample_rate=16000, n_mels=80)\n",
    "logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel = torch.load(\"E:\\Datasets\\VoxCeleb1\\subset\\\\features_3\\\\train\\id10075\\\\08H4--mL1LQ\\\\00001_.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logeml = logmel + 1e-6\n",
    "logeml = torch.log(logeml)\n",
    "logmel = F.instance_norm(logmel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(melspec[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_masking = T.FrequencyMasking(freq_mask_param=10)\n",
    "time_masking = T.TimeMasking(time_mask_param=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_logmel = time_masking(freq_masking(logmel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_spectrogram(time_masking(freq_masking(logmel))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_secs = 3\n",
    "csv_base_path: str = \"E:/Datasets/VoxCeleb1/subset/\"\n",
    "label_dict = pd.read_csv(\n",
    "    csv_base_path + f\"subset_labels_{num_secs}.csv\"\n",
    ").to_dict()[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_ids = list(label_dict.keys())\n",
    "len(speaker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(\n",
    "    num_speakers=100, \n",
    "    to_db_flag=True,\n",
    "    cmn_flag=True,\n",
    "    clip_secs=4,\n",
    "    n_fft=400,\n",
    "    win_length=400,\n",
    "    hop_length=160,\n",
    "    n_mels=80,\n",
    "    power=1.0,\n",
    "    data_aug=False,\n",
    "    speaker_ids=speaker_ids,\n",
    "    full_test=True,\n",
    "    wave_test=True\n",
    "    # base_path=\"/media/gabriele/Seagate Expansion Drive/Datasets/VoxCeleb1/\",\n",
    "    # noise_dir=\"/media/gabriele/Seagate Expansion Drive/Datasets/Musan/noise\",\n",
    "    # babble_dir=\"/media/gabriele/Seagate Expansion Drive/Datasets/Musan/speech\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"E:\\Datasets\\VoxCeleb1\\subset\\subset_labels_3.csv\")\n",
    "speaker_ids = df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_dataset(\n",
    "    num_speakers=5,\n",
    "    clip_secs=6, \n",
    "    to_db_flag=True, \n",
    "    cmn_flag=True,\n",
    "    speaker_ids=speaker_ids\n",
    "    # base_path=\"/media/gabriele/Seagate Expansion Drive/Datasets/VoxCeleb1/\",\n",
    "    # noise_dir=\"/media/gabriele/Seagate Expansion Drive/Datasets/Musan/noise\",\n",
    "    # babble_dir=\"/media/gabriele/Seagate Expansion Drive/Datasets/Musan/speech\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_secs = 4\n",
    "csv_base_path: str = \"E:/Datasets/VoxCeleb1/subset/\"\n",
    "set_name: str = \"train\"\n",
    "df = pd.read_csv(\n",
    "            csv_base_path + f\"subset_features_{num_secs}.csv\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59140"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[df[\"Set\"] == \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df[df[\"Set\"] == \"train\"]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = pd.read_csv(\n",
    "            csv_base_path + f\"subset_labels_{num_secs}.csv\"\n",
    "        ).to_dict()[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melspecs = []\n",
    "y = []\n",
    "for idx, row in df.iterrows():\n",
    "    melspec = torch.load(row[\"File\"]).numpy()\n",
    "    melspecs.append(\n",
    "        melspec\n",
    "    )\n",
    "    y.append(\n",
    "        label_dict[row[\"Speaker\"]]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack(melspecs)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.reshape(X.shape[0], 80*301)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.vstack(y).squeeze(-1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpca = pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_y = np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xpca[y == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in u_y:\n",
    "    plt.scatter(\n",
    "        Xpca[y == label, 0], \n",
    "        Xpca[y == label, 1], \n",
    "        label=label,\n",
    "        alpha=0.7\n",
    "    )\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = svc.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mlp.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    [torch.randn((4,5))], \n",
    "    lr=1e-3, \n",
    "    eps=1e-8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.state_dict()[\"param_groups\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.randint(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform = torch.load(\n",
    "    \"E:\\Datasets\\VoxCeleb1\\subset\\\\features_4\\\\train\\id10206\\\\0dATli9-ofc\\\\00001_.pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel = extract_logmel(waveform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logmel.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = pad_tensor(\n",
    "    logmel, 401, 450\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_secs = 4\n",
    "csv_base_path: str = \"E:/Datasets/VoxCeleb1/subset/\"\n",
    "label_dict = pd.read_csv(\n",
    "    csv_base_path + f\"subset_labels_{num_secs}.csv\"\n",
    ").to_dict()[\"label\"]\n",
    "\n",
    "speaker_ids = list(label_dict.keys())\n",
    "len(speaker_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_base_path: str = \"E:/Datasets/VoxCeleb1/subset/\"\n",
    "ver_df = pd.read_csv(\n",
    "    csv_base_path + f\"subset_verification_4.csv\"\n",
    ")\n",
    "ver_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_ids = ver_df[\"Speaker\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_verification_dataset(\n",
    "    speaker_ids=speaker_ids,\n",
    "    num_speakers=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dataset_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred, y_true = train_sklearn_model(\n",
    "    svc,\n",
    "    limited_train=50\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(0.13984962406015036 * 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_score(y_true, y_pred, average=\"weighted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(0.6425952911376953 * 100, 2), round(0.0480, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_plot(limited_train=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.load(\n",
    "   \"E:\\Datasets\\VoxCeleb1\\subset\\\\features_4\\\\train\\id10118\\_QrOkTwSOeE\\\\00001_.pt\" \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n",
      "Got the dataframes\n",
      "To analyze entire dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analyzing entire dataset: 100%|██████████| 153516/153516 [36:36<00:00, 69.89it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished analysis of entire dataset\n",
      "********************\n",
      "GENERAL STATS\n",
      "********************\n",
      "Samples in entire dataset: 153516\n",
      "Samples in identification subset (without augment): 13042\n",
      "Samples in verification subset: 758\n",
      "Speakers in entire dataset: 1251\n",
      "Speakers in identification subset: 100\n",
      "Speakers in verification subset: 10\n",
      "Gender in entire dataset:\n",
      "m    0.55\n",
      "f    0.45\n",
      "Name: Gender, dtype: float64\n",
      "Gender in identification subset:\n",
      "m    0.55\n",
      "f    0.45\n",
      "dtype: float64\n",
      "Gender in verification subset:\n",
      "m    0.5\n",
      "f    0.5\n",
      "dtype: float64\n",
      "Nationality in entire dataset:\n",
      "USA                    0.64\n",
      "UK                     0.17\n",
      "Canada                 0.04\n",
      "Australia              0.03\n",
      "India                  0.02\n",
      "Norway                 0.02\n",
      "Ireland                0.01\n",
      "Germany                0.01\n",
      "New Zealand            0.01\n",
      "Italy                  0.01\n",
      "Mexico                 0.01\n",
      "Sweden                 0.00\n",
      "Russia                 0.00\n",
      "Spain                  0.00\n",
      "Philippines            0.00\n",
      "Croatia                0.00\n",
      "Denmark                0.00\n",
      "Netherlands            0.00\n",
      "Switzerland            0.00\n",
      "Chile                  0.00\n",
      "China                  0.00\n",
      "Poland                 0.00\n",
      "Portugal               0.00\n",
      "South Korea            0.00\n",
      "Pakistan               0.00\n",
      "Sudan                  0.00\n",
      "Guyana                 0.00\n",
      "Sri Lanka              0.00\n",
      "Singapore              0.00\n",
      "France                 0.00\n",
      "Israel                 0.00\n",
      "Brazil                 0.00\n",
      "Trinidad and Tobago    0.00\n",
      "Austria                0.00\n",
      "South Africa           0.00\n",
      "Iran                   0.00\n",
      "Name: Nationality, dtype: float64\n",
      "Nationality in identification subset:\n",
      "USA            0.59\n",
      "UK             0.19\n",
      "Australia      0.04\n",
      "Canada         0.02\n",
      "India          0.02\n",
      "Russia         0.02\n",
      "Norway         0.02\n",
      "China          0.01\n",
      "Sudan          0.01\n",
      "Germany        0.01\n",
      "Mexico         0.01\n",
      "New Zealand    0.01\n",
      "Spain          0.01\n",
      "Netherlands    0.01\n",
      "Chile          0.01\n",
      "Ireland        0.01\n",
      "Italy          0.01\n",
      "dtype: float64\n",
      "Nationality in verification subset:\n",
      "USA      0.8\n",
      "Spain    0.1\n",
      "UK       0.1\n",
      "dtype: float64\n",
      "Mean seconds in entire dataset: 8.25\n",
      "Std seconds in entire dataset: 5.31\n",
      "Mean seconds in verification dataset: 8.05\n",
      "Std seconds in verification dataset: 5.14\n",
      "Subset now counting samples insteadof speakers (this is the reason why some numbers are different)\n",
      "********************\n",
      "SUBSET SET\n",
      "********************\n",
      "Number of samples: 60354\n",
      "Nationality:\n",
      "USA            0.55\n",
      "UK             0.20\n",
      "Australia      0.04\n",
      "India          0.04\n",
      "Russia         0.03\n",
      "Canada         0.02\n",
      "China          0.02\n",
      "Sudan          0.02\n",
      "Norway         0.01\n",
      "New Zealand    0.01\n",
      "Netherlands    0.01\n",
      "Mexico         0.01\n",
      "Germany        0.01\n",
      "Ireland        0.01\n",
      "Chile          0.00\n",
      "Spain          0.00\n",
      "Italy          0.00\n",
      "dtype: float64\n",
      "Gender:\n",
      "m    0.6\n",
      "f    0.4\n",
      "dtype: float64\n",
      "Seconds:\n",
      "Mean: 8.2; Std: 5.35\n",
      "********************\n",
      "TRAIN SET\n",
      "********************\n",
      "Number of samples: 11828\n",
      "Nationality:\n",
      "USA            0.55\n",
      "UK             0.20\n",
      "Australia      0.04\n",
      "India          0.04\n",
      "Russia         0.03\n",
      "Canada         0.02\n",
      "China          0.02\n",
      "Sudan          0.02\n",
      "New Zealand    0.01\n",
      "Norway         0.01\n",
      "Netherlands    0.01\n",
      "Mexico         0.01\n",
      "Germany        0.01\n",
      "Ireland        0.01\n",
      "Chile          0.00\n",
      "Spain          0.00\n",
      "Italy          0.00\n",
      "dtype: float64\n",
      "Gender:\n",
      "m    0.6\n",
      "f    0.4\n",
      "dtype: float64\n",
      "Seconds:\n",
      "Mean: 8.23; Std: 5.41\n",
      "********************\n",
      "TEST SET\n",
      "********************\n",
      "Number of samples: 665\n",
      "Nationality:\n",
      "USA            0.57\n",
      "UK             0.22\n",
      "Australia      0.04\n",
      "Norway         0.02\n",
      "Canada         0.02\n",
      "Russia         0.02\n",
      "India          0.02\n",
      "Italy          0.02\n",
      "Sudan          0.01\n",
      "Chile          0.01\n",
      "Mexico         0.01\n",
      "China          0.01\n",
      "Ireland        0.01\n",
      "New Zealand    0.01\n",
      "Spain          0.01\n",
      "Netherlands    0.01\n",
      "Germany        0.01\n",
      "dtype: float64\n",
      "Gender:\n",
      "m    0.57\n",
      "f    0.43\n",
      "dtype: float64\n",
      "Seconds:\n",
      "Mean: 7.72; Std: 4.65\n"
     ]
    }
   ],
   "source": [
    "get_dataset_stats()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f3a0b09ceef9b827a17ce91fbca1b0359a993a122e166af5f0b6d31a5625f693"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('tf_p3.9': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
